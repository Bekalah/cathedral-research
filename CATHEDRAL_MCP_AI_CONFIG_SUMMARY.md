# Cathedral MCP/AI Configuration Summary

## MCP Server & AI Setup
- **Workspace Name:** cathedral-development-staging
- **Azure Foundry Subscription:** 88235353-b821-4046-9457-89f70c3d8e9e (East US)
- **Recommended Models:**
  - Coding: gpt-4o, gpt-4o-mini, codex-mini
  - Reasoning: DeepSeek-R1, o1-mini, Phi-4-reasoning
  - Multimodal: gpt-4o, Phi-4-multimodal-instruct
  - Image Generation: dall-e-3, Stable-Diffusion-3.5-Large
- **GitHub Copilot:** Pro enabled (chat, code completion, code explanation)

## Technology Stack
- Vite + React + Three.js
- Always use interactive 3D, modular components, ND-safe design
- Never use flat HTML, SVG-only, static sites

## Deployment Pipeline
1. Develop in BUILDING CATHEDRALS workspace
2. Build with Vite
3. Deploy to production repos
4. Live at GitHub Pages: bekalah.github.io/cathedral

## Repository Connections
- Main: Bekalah/cathedral
- Supporting: cathedral-technical, cathedral-research, cathedral-docs, BUILDING-CATHEDRALS
- Specialized: codex-14499, liber-arcanae, circuitum99

## Recovery & Troubleshooting
- If MCP/AI is broken, check `BUILDING_CATHEDRALS_ARCHIVE/ai-config.json` for correct settings
- Ensure Azure Foundry and GitHub Copilot are enabled and connected
- Use recommended models for coding, reasoning, and multimodal tasks

## Next Steps
- Validate your Azure and Copilot trial status
- If issues persist, re-authenticate and check subscription/region
- Document any errors for support
